{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# RegressionTrustee\n\nSimple example on how to use the ClassificationTrustee class to extract\na decision tree from a MLPRegressor (neural network) from scikit-learn.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# importing required libraries\n# importing Scikit-learn library and datasets package\nimport graphviz\n\nfrom sklearn import tree\nfrom sklearn import datasets\nfrom sklearn.neural_network import MLPRegressor\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import r2_score\n\nfrom trustee import RegressionTrustee\n\n# Loading the diabetes dataset (regression)\ndiabetes = datasets.load_diabetes()\nX, y = datasets.load_diabetes(return_X_y=True)\n# Spliting arrays or matrices into random train and test subsets\n# i.e. 70 % training dataset and 30 % test datasets\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30)\n\n# creating a MLP regressor\nclf = MLPRegressor(solver=\"lbfgs\", alpha=1e-5, hidden_layer_sizes=(100, 50), max_iter=500, random_state=1)\n# Training the model on the training dataset\n# fit function is used to train the model using the training sets as parameters\nclf.fit(X_train, y_train)\n# performing predictions on the test dataset\ny_pred = clf.predict(X_test)\n\n# Evaluate model accuracy\nprint(\"Model R2-score:\")\nprint(r2_score(y_test, y_pred))\n\n# Initialize Trustee and fit for classification models\ntrustee = RegressionTrustee(expert=clf)\ntrustee.fit(X_train, y_train, num_iter=50, num_stability_iter=10, samples_size=0.3, verbose=True)\n\n# Get the best explanation from Trustee\ndt, pruned_dt, agreement, reward = trustee.explain()\nprint(f\"Model explanation training (agreement, fidelity): ({agreement}, {reward})\")\nprint(f\"Model Explanation size: {dt.tree_.node_count}\")\nprint(f\"Top-k Prunned Model explanation size: {pruned_dt.tree_.node_count}\")\n\n# Use explanations to make predictions\ndt_y_pred = dt.predict(X_test)\npruned_dt_y_pred = pruned_dt.predict(X_test)\n\n# Evaluate accuracy and fidelity of explanations\nprint(\"Model explanation global fidelity:\")\nprint(r2_score(y_pred, dt_y_pred))\nprint(\"Top-k Model explanation global fidelity:\")\nprint(r2_score(y_pred, pruned_dt_y_pred))\n\nprint(\"Model explanation R2-score:\")\nprint(r2_score(y_test, dt_y_pred))\nprint(\"Top-k Model explanation R2-score:\")\nprint(r2_score(y_test, pruned_dt_y_pred))\n\n# Output decision tree to pdf\ndot_data = tree.export_graphviz(\n    dt,\n    feature_names=diabetes.feature_names,\n    filled=True,\n    rounded=True,\n    special_characters=True,\n)\ngraph = graphviz.Source(dot_data)\ngraph.render(\"dt_explanation\")\n\n# Output pruned decision tree to pdf\ndot_data = tree.export_graphviz(\n    pruned_dt,\n    feature_names=diabetes.feature_names,\n    filled=True,\n    rounded=True,\n    special_characters=True,\n)\ngraph = graphviz.Source(dot_data)\ngraph.render(\"pruned_dt_explation\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}